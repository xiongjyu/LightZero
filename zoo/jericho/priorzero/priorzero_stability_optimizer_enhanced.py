"""
PriorZero ç¨³å®šæ€§ä¼˜åŒ–æ¨¡å— - å¢å¼ºé²æ£’ç‰ˆæœ¬

åŸºäºå­¦è€…è¯„å®¡æ„è§çš„å…³é”®æ”¹è¿›ï¼š
1. âœ… ä¿®å¤ Welford æ— é™è®°å¿†é—®é¢˜ - ä½¿ç”¨ Batch Welford + EMA
2. âœ… æ·»åŠ å¼ºåˆ¶å¯åŠ¨ä¿åº•æœºåˆ¶ - é˜²æ­¢æ­»é”
3. âœ… ä¼˜åŒ–è®­ç»ƒé¢‘ç‡è°ƒèŠ‚é€»è¾‘ - é¿å…æ¶æ€§å¾ªç¯
4. âœ… è½¯æ€§è£å‰ªæ›¿ä»£ç¡¬è£å‰ª - ä¿ç•™ç¨€ç–å¥–åŠ±ä¿¡å·
5. âœ… åˆ†å¸ƒå¼è®­ç»ƒå®‰å…¨ä¿è¯ - ç¡®ä¿å†³ç­–åŒæ­¥

æ ¸å¿ƒæ”¹è¿›ï¼š
- Adaptive Value Normalization - è‡ªé€‚åº”å€¼å½’ä¸€åŒ–
- Curriculum Training Schedule - è¯¾ç¨‹å¼è®­ç»ƒç­–ç•¥
- Gradient & Loss Monitoring - æ¢¯åº¦å’ŒæŸå¤±ç›‘æ§
- Dynamic Training Frequency - åŠ¨æ€è®­ç»ƒé¢‘ç‡è°ƒæ•´
- Distributed Training Safety - åˆ†å¸ƒå¼è®­ç»ƒå®‰å…¨

Date: 2025-12-30
Version: 1.1 Enhanced
"""

import torch
import numpy as np
from typing import Dict, Optional, Tuple
from collections import deque
import logging
import torch.distributed as dist

class AdaptiveValueNormalizer:
    """
    è‡ªé€‚åº”å€¼å½’ä¸€åŒ–å™¨ - å¢å¼ºç‰ˆ

    å…³é”®æ”¹è¿›ï¼ˆåŸºäºå­¦è€…è¯„å®¡ï¼‰:
    1. âœ… Batch Welford + EMA ç»„åˆ - é¿å…æ— é™è®°å¿†é—®é¢˜
    2. âœ… è½¯æ€§è£å‰ªï¼ˆLog-Sym Transformï¼‰- ä¿ç•™ç¨€ç–å¥–åŠ±ä¿¡å·
    3. âœ… è‡ªé€‚åº”åŠ¨é‡ - å‰æœŸå¿«é€Ÿé€‚åº”ï¼ŒåæœŸç¨³å®š

    æ ¸å¿ƒè®¾è®¡ï¼š
    - Welford ç®—æ³•ä»…ç”¨äºå½“å‰ batch çš„ç²¾ç¡®è®¡ç®—ï¼ˆæ•°å€¼ç¨³å®šï¼‰
    - EMA ç”¨äºå…¨å±€ç»Ÿè®¡é‡çš„æ›´æ–°ï¼ˆé€‚åº”éå¹³ç¨³åˆ†å¸ƒï¼‰
    - Log-Sym å˜æ¢è€Œéç¡¬è£å‰ªï¼ˆä¿ç•™å¤§å¥–åŠ±æ¢¯åº¦ï¼‰
    """

    def __init__(
        self,
        init_momentum: float = 0.9,          # åˆå§‹ EMA åŠ¨é‡
        final_momentum: float = 0.99,        # æœ€ç»ˆ EMA åŠ¨é‡
        warmup_steps: int = 100,             # çƒ­å¯åŠ¨æ­¥æ•°
        clip_method: str = 'soft',           # 'soft' (log-sym) or 'hard' (percentile)
        clip_percentile: float = 0.95,       # ç¡¬è£å‰ªç™¾åˆ†ä½ï¼ˆä»…å½“ clip_method='hard'ï¼‰
        min_std: float = 1e-6,               # æœ€å°æ ‡å‡†å·®
        use_welford: bool = True,            # ä½¿ç”¨ Welford ç®—æ³•
    ):
        self.init_momentum = init_momentum
        self.final_momentum = final_momentum
        self.warmup_steps = warmup_steps
        self.clip_method = clip_method
        self.clip_percentile = clip_percentile
        self.min_std = min_std
        self.use_welford = use_welford

        # EMA è¿è¡Œç»Ÿè®¡é‡ï¼ˆå…¨å±€ï¼‰
        self.running_mean = 0.0
        self.running_std = 1.0
        self.update_count = 0

        # History for monitoring
        self.value_history = deque(maxlen=1000)

        # Statistics
        self.stats = {
            'batch_means': [],
            'batch_stds': [],
            'running_means': [],
            'running_stds': [],
            'clipped_counts': [],
        }

    def get_current_momentum(self) -> float:
        """è®¡ç®—å½“å‰çš„ EMA åŠ¨é‡ï¼ˆä»å¿«åˆ°æ…¢ï¼‰"""
        if self.update_count >= self.warmup_steps:
            return self.final_momentum

        # Linear interpolation during warmup
        progress = self.update_count / self.warmup_steps
        return self.init_momentum + (self.final_momentum - self.init_momentum) * progress

    def compute_batch_stats_welford(self, values: np.ndarray) -> Tuple[float, float]:
        """
        ä½¿ç”¨ NumPy çš„é«˜ç²¾åº¦å®ç°æ›¿ä»£ Python å¾ªç¯
        NumPy çš„ var å®ç°å†…éƒ¨å·²ç»ä½¿ç”¨äº†æ•°å€¼ç¨³å®šçš„ç®—æ³•
        """
        if len(values) == 0:
            return 0.0, 1.0
        
        # ä½¿ç”¨ float64 è¿›è¡Œè®¡ç®—ä»¥ä¿è¯ç²¾åº¦ï¼Œé¿å… Python å¾ªç¯
        values_f64 = values.astype(np.float64).flatten()
        mean = np.mean(values_f64)
        std = np.std(values_f64, ddof=1) # ddof=1 for unbiased estimator (n-1)
        
        return float(mean), max(float(std), self.min_std)
        
    # def compute_batch_stats_welford(self, values: np.ndarray) -> Tuple[float, float]:
    #     """
    #     ä½¿ç”¨ Welford ç®—æ³•è®¡ç®—å½“å‰ batch çš„ç²¾ç¡®ç»Ÿè®¡é‡

    #     å…³é”®æ”¹è¿›ï¼šä»…ç”¨äº batch å†…è®¡ç®—ï¼Œä¸ç´¯ç§¯å†å²
    #     è¿™æ ·æ—¢ä¿è¯æ•°å€¼ç¨³å®šï¼Œåˆé¿å…äº†"æ— é™è®°å¿†"é—®é¢˜
    #     """
    #     if len(values) == 0:
    #         return 0.0, 1.0

    #     values_flat = values.flatten()
    #     n = len(values_flat)

    #     if n == 1:
    #         return float(values_flat[0]), self.min_std

    #     # Welford's algorithm for batch statistics
    #     mean = 0.0
    #     M2 = 0.0

    #     for i, value in enumerate(values_flat, 1):
    #         delta = value - mean
    #         mean += delta / i
    #         delta2 = value - mean
    #         M2 += delta * delta2

    #     variance = M2 / (n - 1) if n > 1 else 0.0
    #     std = np.sqrt(variance)

    #     return float(mean), max(float(std), self.min_std)

    def soft_clip_log_sym(self, values: np.ndarray) -> Tuple[np.ndarray, int]:
        """
        è½¯æ€§è£å‰ª - Log-Symmetric Transform

        f(x) = sign(x) * log(1 + |x|)

        ä¼˜åŠ¿ï¼š
        - ä¿ç•™å¤§å¥–åŠ±çš„æ¢¯åº¦ä¿¡å·ï¼ˆç¨€ç–å¥–åŠ±å‹å¥½ï¼‰
        - é™åˆ¶æ•°å€¼èŒƒå›´ï¼Œé˜²æ­¢æ¢¯åº¦çˆ†ç‚¸
        - å¯å¾®åˆ†ï¼Œé€‚åˆåå‘ä¼ æ’­
        """
        original_values = values.copy()
        values_transformed = np.sign(values) * np.log1p(np.abs(values))

        # Count how many values were significantly transformed (|x| > 10)
        significant_transform = np.sum(np.abs(original_values) > 10)

        return values_transformed, significant_transform

    def hard_clip_percentile(self, values: np.ndarray) -> Tuple[np.ndarray, int]:
        """
        ç¡¬è£å‰ª - åŸºäºç™¾åˆ†ä½æ•°

        ä»…ç”¨äºéç¨€ç–å¥–åŠ±ç¯å¢ƒï¼ˆå¦‚ Atariï¼‰
        """
        if self.update_count < 10:  # Skip clipping in early phase
            return values, 0

        percentile_low = (1 - self.clip_percentile) / 2 * 100
        percentile_high = (1 + self.clip_percentile) / 2 * 100
        lower_bound = np.percentile(values, percentile_low)
        upper_bound = np.percentile(values, percentile_high)

        original_values = values.copy()
        values_clipped = np.clip(values, lower_bound, upper_bound)
        clipped_count = np.sum(original_values != values_clipped)

        return values_clipped, clipped_count

    def normalize(
        self,
        values: torch.Tensor,
        clip_values: bool = True,
        return_stats: bool = False,
    ) -> torch.Tensor | Tuple[torch.Tensor, Dict]:
        """
        å½’ä¸€åŒ–å€¼ - å¢å¼ºç‰ˆ

        æµç¨‹ï¼š
        1. Welford è®¡ç®— batch ç²¾ç¡®ç»Ÿè®¡é‡
        2. EMA æ›´æ–°å…¨å±€è¿è¡Œç»Ÿè®¡é‡
        3. è½¯æ€§/ç¡¬æ€§è£å‰ª
        4. å½’ä¸€åŒ–

        Args:
            values: è¾“å…¥å€¼ [B] æˆ– [B, T]
            clip_values: æ˜¯å¦è£å‰ªå¼‚å¸¸å€¼
            return_stats: æ˜¯å¦è¿”å›ç»Ÿè®¡ä¿¡æ¯
        """
        values_np = values.detach().cpu().numpy()

        # Step 1: Compute batch statistics with Welford (æ•°å€¼ç¨³å®š)
        if self.use_welford:
            batch_mean, batch_std = self.compute_batch_stats_welford(values_np)
        else:
            batch_mean = float(values_np.mean())
            batch_std = max(float(values_np.std()), self.min_std)

        # Step 2: Apply clipping (optional)
        clipped_count = 0
        if clip_values:
            if self.clip_method == 'soft':
                values_np, clipped_count = self.soft_clip_log_sym(values_np)
                # Recompute stats after soft transform
                if self.use_welford:
                    batch_mean, batch_std = self.compute_batch_stats_welford(values_np)
                else:
                    batch_mean = float(values_np.mean())
                    batch_std = max(float(values_np.std()), self.min_std)
            elif self.clip_method == 'hard':
                values_np, clipped_count = self.hard_clip_percentile(values_np)
                # Recompute stats after hard clip
                if self.use_welford:
                    batch_mean, batch_std = self.compute_batch_stats_welford(values_np)
                else:
                    batch_mean = float(values_np.mean())
                    batch_std = max(float(values_np.std()), self.min_std)

        # Step 3: Update running statistics with EMA (é€‚åº”éå¹³ç¨³)
        momentum = self.get_current_momentum()

        if self.update_count == 0:
            self.running_mean = batch_mean
            self.running_std = batch_std
        else:
            self.running_mean = momentum * self.running_mean + (1 - momentum) * batch_mean
            self.running_std = momentum * self.running_std + (1 - momentum) * batch_std

        self.update_count += 1
        self.value_history.extend(values_np.flatten().tolist())

        # Step 4: Normalize
        normalized = (torch.from_numpy(values_np).to(values.device) - self.running_mean) / (self.running_std + self.min_std)

        # Record statistics
        stats = {
            'batch_mean': batch_mean,
            'batch_std': batch_std,
            'running_mean': self.running_mean,
            'running_std': self.running_std,
            'clipped_count': clipped_count,
            'total_count': len(values_np.flatten()),
            'current_momentum': momentum,
            'clip_method': self.clip_method,
        }

        # Store for analysis
        self.stats['batch_means'].append(batch_mean)
        self.stats['batch_stds'].append(batch_std)
        self.stats['running_means'].append(self.running_mean)
        self.stats['running_stds'].append(self.running_std)
        self.stats['clipped_counts'].append(clipped_count)

        if return_stats:
            return normalized, stats
        return normalized

    def get_summary_stats(self) -> Dict:
        """è·å–æ±‡æ€»ç»Ÿè®¡ä¿¡æ¯"""
        if self.update_count == 0:
            return {}

        recent_n = min(100, len(self.value_history))
        recent_values = list(self.value_history)[-recent_n:]

        return {
            'total_updates': self.update_count,
            'current_mean': self.running_mean,
            'current_std': self.running_std,
            'recent_mean': np.mean(recent_values) if recent_values else 0.0,
            'recent_std': np.std(recent_values) if recent_values else 1.0,
            'recent_min': np.min(recent_values) if recent_values else 0.0,
            'recent_max': np.max(recent_values) if recent_values else 0.0,
            'clip_method': self.clip_method,
        }


class CurriculumTrainingScheduler:
    """
    è¯¾ç¨‹å¼è®­ç»ƒè°ƒåº¦å™¨ - å¢å¼ºç‰ˆ

    å…³é”®æ”¹è¿›ï¼ˆåŸºäºå­¦è€…è¯„å®¡ï¼‰:
    1. âœ… å¼ºåˆ¶å¯åŠ¨ä¿åº•æœºåˆ¶ - é˜²æ­¢æ­»é”
    2. âœ… ä¼˜åŒ–è®­ç»ƒé¢‘ç‡é€»è¾‘ - é¿å…æ¶æ€§å¾ªç¯
    3. âœ… é˜ˆå€¼éœ‡è¡é˜²æŠ¤ - æ·»åŠ  hysteresis

    æ ¸å¿ƒåŠŸèƒ½ï¼š
    1. World Model Warm-up: å…ˆè®­ç»ƒ WM ä½¿å…¶ value é¢„æµ‹å‡†ç¡®
    2. Dynamic Training Ratio: åŠ¨æ€è°ƒæ•´ WM/LLM è®­ç»ƒé¢‘ç‡
    3. Progressive Difficulty: é€æ­¥å¢åŠ  LLM è®­ç»ƒé¢‘ç‡
    4. Stability Monitoring: ç›‘æ§è®­ç»ƒç¨³å®šæ€§è‡ªåŠ¨è°ƒæ•´
    """

    def __init__(
        self,
        wm_warmup_steps: int = 500,                 # WM é¢„çƒ­æ­¥æ•°
        wm_warmup_update_ratio: int = 5,            # é¢„çƒ­æœŸ WM æ¯æ¬¡ collect è®­ç»ƒæ¬¡æ•°
        llm_start_threshold: float = 0.3,           # LLM å¼€å§‹è®­ç»ƒçš„ value å‡†ç¡®åº¦é˜ˆå€¼
        llm_start_hysteresis: float = 0.05,         # é˜ˆå€¼æ»åï¼ˆé˜²æ­¢éœ‡è¡ï¼‰
        max_warmup_steps_hard_limit: int = 2000,    # å¼ºåˆ¶å¯åŠ¨ä¸Šé™ï¼ˆé˜²æ­¢æ­»é”ï¼‰
        min_llm_update_interval: int = 1,           # LLM æœ€å°æ›´æ–°é—´éš”
        max_llm_update_interval: int = 10,          # LLM æœ€å¤§æ›´æ–°é—´éš”
        min_llm_update_interval_hard: int = 1,      # LLM æœ€å°æ›´æ–°é—´éš”ï¼ˆç¡¬é™åˆ¶ï¼Œé¿å…æ•°æ®è¿‡æ—¶ï¼‰
        stability_window: int = 50,                 # ç¨³å®šæ€§ç›‘æ§çª—å£
    ):
        self.wm_warmup_steps = wm_warmup_steps
        self.wm_warmup_update_ratio = wm_warmup_update_ratio
        self.llm_start_threshold = llm_start_threshold
        self.llm_start_hysteresis = llm_start_hysteresis
        self.max_warmup_steps_hard_limit = max_warmup_steps_hard_limit
        self.min_llm_update_interval = min_llm_update_interval
        self.max_llm_update_interval = max_llm_update_interval
        self.min_llm_update_interval_hard = min_llm_update_interval_hard
        self.stability_window = stability_window

        # State
        self.current_step = 0
        self.llm_update_count = 0
        self.wm_update_count = 0

        # Metrics history
        self.value_prediction_errors = deque(maxlen=stability_window)
        self.llm_losses = deque(maxlen=stability_window)
        self.wm_losses = deque(maxlen=stability_window)

        # Flags
        self.llm_training_enabled = False
        self.llm_ever_enabled = False  # é˜²æ­¢éœ‡è¡ï¼šä¸€æ—¦å¯ç”¨å°±ä¸å†ç¦ç”¨
        self.is_warming_up = True

    def should_train_wm(self, new_data_collected: bool = True) -> Tuple[bool, int]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è®­ç»ƒ World Model

        Returns:
            should_train: æ˜¯å¦è®­ç»ƒ
            num_updates: è®­ç»ƒæ¬¡æ•°
        """
        if not new_data_collected:
            return False, 0

        if self.is_warming_up:
            # Warm-up æœŸé—´æ¯æ¬¡éƒ½è®­ç»ƒï¼Œä¸”è®­ç»ƒæ¬¡æ•°æ›´å¤š
            return True, self.wm_warmup_update_ratio
        else:
            # æ­£å¸¸è®­ç»ƒæœŸé—´
            return True, 1  # æˆ–è€…æ ¹æ®é…ç½®è¿”å› update_per_collect

    def should_train_llm(
        self,
        new_samples: int,
        value_prediction_accuracy: Optional[float] = None,
    ) -> Tuple[bool, Dict]:
        """
        åˆ¤æ–­æ˜¯å¦åº”è¯¥è®­ç»ƒ LLM - å¢å¼ºç‰ˆ

        æ”¹è¿›ï¼š
        1. âœ… å¼ºåˆ¶å¯åŠ¨ä¿åº•æœºåˆ¶
        2. âœ… Hysteresis é˜²æ­¢éœ‡è¡
        3. âœ… æœ€å°é¢‘ç‡é™åˆ¶é¿å…æ•°æ®è¿‡æ—¶

        Args:
            new_samples: æ–°æ”¶é›†çš„æ ·æœ¬æ•°
            value_prediction_accuracy: WM çš„ value é¢„æµ‹å‡†ç¡®åº¦ (R^2 or 1 - MAPE)

        Returns:
            should_train: æ˜¯å¦è®­ç»ƒ
            info: å†³ç­–ä¿¡æ¯
        """
        info = {
            'reason': '',
            'current_step': self.current_step,
            'llm_training_enabled': self.llm_training_enabled,
            'is_warming_up': self.is_warming_up,
        }

        # ========================================================================
        # å¼ºåˆ¶å¯åŠ¨ä¿åº•æœºåˆ¶ï¼ˆé˜²æ­¢æ­»é”ï¼‰
        # ========================================================================
        if self.current_step >= self.max_warmup_steps_hard_limit and not self.llm_training_enabled:
            self.llm_training_enabled = True
            self.llm_ever_enabled = True
            self.is_warming_up = False
            logging.warning(
                f"âš  Force-enabled LLM training at step {self.current_step} "
                f"(hard limit {self.max_warmup_steps_hard_limit} reached)"
            )
            info['reason'] = 'Force start: Max warmup steps reached'
            # ç»§ç»­æ‰§è¡Œåç»­é€»è¾‘

        # ========================================================================
        # Check warm-up phase
        # ========================================================================
        if self.current_step < self.wm_warmup_steps:
            info['reason'] = f'WM warming up ({self.current_step}/{self.wm_warmup_steps})'
            return False, info

        # ========================================================================
        # Enable LLM training after warm-up (with hysteresis)
        # ========================================================================
        if not self.llm_training_enabled:
            if value_prediction_accuracy is not None:
                # ä½¿ç”¨ hysteresisï¼šå¯ç”¨æ—¶è¦æ±‚ >= thresholdï¼Œç¦ç”¨æ—¶è¦æ±‚ < threshold - hysteresis
                if value_prediction_accuracy >= self.llm_start_threshold:
                    self.llm_training_enabled = True
                    self.llm_ever_enabled = True
                    self.is_warming_up = False
                    logging.info(
                        f"âœ“ LLM training enabled! Value prediction accuracy: {value_prediction_accuracy:.3f} "
                        f">= threshold {self.llm_start_threshold}"
                    )
                else:
                    info['reason'] = (
                        f'Value accuracy {value_prediction_accuracy:.3f} < '
                        f'threshold {self.llm_start_threshold}'
                    )
                    return False, info
            else:
                # Fallback: enable after warmup even without accuracy metric
                self.llm_training_enabled = True
                self.llm_ever_enabled = True
                self.is_warming_up = False
                logging.warning("Value accuracy not provided, enabling LLM training after warmup")

        # ========================================================================
        # é˜²æ­¢éœ‡è¡ï¼šä¸€æ—¦å¯ç”¨å°±ä¸å†ç¦ç”¨ï¼ˆé™¤éæ˜ç¡®é‡ç½®ï¼‰
        # ========================================================================
        if self.llm_ever_enabled and not self.llm_training_enabled:
            if value_prediction_accuracy is not None:
                # åªæœ‰åœ¨å‡†ç¡®åº¦ä¸¥é‡ä¸‹é™æ—¶æ‰ç¦ç”¨ï¼ˆä½¿ç”¨ hysteresisï¼‰
                if value_prediction_accuracy >= self.llm_start_threshold - self.llm_start_hysteresis:
                    self.llm_training_enabled = True

        # Check sample count
        if new_samples <= 0:
            info['reason'] = 'No new samples'
            return False, info

        # Dynamic update interval based on stability
        update_interval = self._compute_llm_update_interval()

        # ========================================================================
        # æœ€å°é¢‘ç‡é™åˆ¶ï¼ˆé˜²æ­¢æ•°æ®è¿‡æ—¶ï¼‰
        # ========================================================================
        update_interval = max(update_interval, self.min_llm_update_interval_hard)

        steps_since_last_update = self.current_step - self.llm_update_count * update_interval
        if steps_since_last_update >= update_interval:
            info['reason'] = f'Update interval reached ({steps_since_last_update} >= {update_interval})'
            return True, info
        else:
            info['reason'] = f'Waiting for update interval ({steps_since_last_update}/{update_interval})'
            return False, info

    def _compute_llm_update_interval(self) -> int:
        """
        æ ¹æ®è®­ç»ƒç¨³å®šæ€§åŠ¨æ€è®¡ç®— LLM æ›´æ–°é—´éš” - ä¼˜åŒ–ç‰ˆ

        æ”¹è¿›ï¼šä¸åº”è¯¥å•çº¯é™ä½é¢‘ç‡ï¼Œè€Œæ˜¯é€šè¿‡å…¶ä»–æ–¹å¼ç¨³å®šè®­ç»ƒ
        è¿™é‡Œä»…ä½œä¸ºå‚è€ƒï¼Œå®é™…ç¨³å®šæ€§åº”é€šè¿‡è°ƒæ•´å­¦ä¹ ç‡ã€æ¢¯åº¦è£å‰ªç­‰å®ç°
        """
        if len(self.llm_losses) < self.stability_window // 2:
            # åˆæœŸä½¿ç”¨é»˜è®¤é—´éš”
            return self.min_llm_update_interval  # æ”¹ä¸ºæœ€å°é—´éš”ï¼Œç¡®ä¿å……åˆ†è®­ç»ƒ

        # è®¡ç®—æŸå¤±çš„å˜åŒ–ç‡ï¼ˆæ ‡å‡†å·®ï¼‰
        recent_losses = list(self.llm_losses)
        loss_std = np.std(recent_losses)
        loss_mean = np.mean(recent_losses)

        if loss_mean == 0:
            cv = float('inf')  # Coefficient of variation
        else:
            cv = loss_std / (abs(loss_mean) + 1e-8)

        # CV è¶Šå° -> è¶Šç¨³å®š -> ä¿æŒå½“å‰é¢‘ç‡
        # CV è¶Šå¤§ -> ä¸ç¨³å®š -> ç•¥å¾®é™ä½é¢‘ç‡ä½†ä¸è¿‡åˆ†ï¼ˆé˜²æ­¢æ•°æ®è¿‡æ—¶ï¼‰
        if cv < 0.1:  # Very stable
            interval = self.min_llm_update_interval
        elif cv < 0.3:  # Moderately stable
            interval = (self.min_llm_update_interval + self.max_llm_update_interval) // 2
        else:  # Unstable
            # ä¸è¿‡åˆ†é™ä½é¢‘ç‡ï¼Œæœ€å¤šåˆ° max çš„ä¸€åŠ
            interval = min(self.max_llm_update_interval // 2, self.max_llm_update_interval)

        return interval

    def record_metrics(
        self,
        wm_loss: Optional[float] = None,
        llm_loss: Optional[float] = None,
        value_pred_error: Optional[float] = None,
    ):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡"""
        if wm_loss is not None:
            self.wm_losses.append(wm_loss)
            self.wm_update_count += 1

        if llm_loss is not None:
            self.llm_losses.append(llm_loss)
            self.llm_update_count += 1

        if value_pred_error is not None:
            self.value_prediction_errors.append(value_pred_error)

    def step(self):
        """å‰è¿›ä¸€æ­¥"""
        self.current_step += 1

    def get_value_prediction_accuracy(self) -> Optional[float]:
        """
        è®¡ç®— value é¢„æµ‹å‡†ç¡®åº¦

        Returns:
            accuracy: å‡†ç¡®åº¦ (1 - MAPE)ï¼ŒèŒƒå›´ [0, 1]
        """
        if len(self.value_prediction_errors) == 0:
            return None

        # ä½¿ç”¨ MAPE (Mean Absolute Percentage Error)
        mape = np.mean(list(self.value_prediction_errors))
        accuracy = max(0.0, 1.0 - mape)
        return accuracy

    def get_summary_stats(self) -> Dict:
        """è·å–æ±‡æ€»ç»Ÿè®¡"""
        return {
            'current_step': self.current_step,
            'wm_update_count': self.wm_update_count,
            'llm_update_count': self.llm_update_count,
            'llm_training_enabled': self.llm_training_enabled,
            'llm_ever_enabled': self.llm_ever_enabled,
            'is_warming_up': self.is_warming_up,
            'value_prediction_accuracy': self.get_value_prediction_accuracy(),
            'recent_wm_loss': np.mean(list(self.wm_losses)) if self.wm_losses else None,
            'recent_llm_loss': np.mean(list(self.llm_losses)) if self.llm_losses else None,
            'llm_loss_stability': 1.0 / (np.std(list(self.llm_losses)) + 1e-8) if len(self.llm_losses) > 1 else 0.0,
        }


class StabilityMonitor:
    """
    è®­ç»ƒç¨³å®šæ€§ç›‘æ§å™¨

    åŠŸèƒ½ï¼š
    1. æ¢¯åº¦ç›‘æ§ï¼šæ£€æµ‹æ¢¯åº¦çˆ†ç‚¸/æ¶ˆå¤±
    2. æŸå¤±ç›‘æ§ï¼šæ£€æµ‹æŸå¤±å‘æ•£
    3. Value åˆ†å¸ƒç›‘æ§ï¼šæ£€æµ‹åˆ†å¸ƒåç§»
    4. è‡ªåŠ¨é¢„è­¦å’Œå»ºè®®
    """

    def __init__(
        self,
        grad_norm_threshold: float = 100.0,
        loss_spike_threshold: float = 3.0,
        value_shift_threshold: float = 2.0,
        window_size: int = 50,
    ):
        self.grad_norm_threshold = grad_norm_threshold
        self.loss_spike_threshold = loss_spike_threshold
        self.value_shift_threshold = value_shift_threshold
        self.window_size = window_size

        # History
        self.wm_grad_norms = deque(maxlen=window_size)
        self.llm_grad_norms = deque(maxlen=window_size)
        self.wm_losses = deque(maxlen=window_size)
        self.llm_losses = deque(maxlen=window_size)
        self.value_means = deque(maxlen=window_size)
        self.value_stds = deque(maxlen=window_size)

        # Warnings
        self.warnings = []

    def check_gradient_health(
        self,
        wm_grad_norm: Optional[float] = None,
        llm_grad_norm: Optional[float] = None,
    ) -> Dict[str, any]:
        """æ£€æŸ¥æ¢¯åº¦å¥åº·çŠ¶æ€"""
        issues = []

        if wm_grad_norm is not None:
            self.wm_grad_norms.append(wm_grad_norm)

            if wm_grad_norm > self.grad_norm_threshold:
                issues.append(f"WM gradient exploding: {wm_grad_norm:.2f}")
            elif wm_grad_norm < 1e-6:
                issues.append(f"WM gradient vanishing: {wm_grad_norm:.2e}")

        if llm_grad_norm is not None:
            self.llm_grad_norms.append(llm_grad_norm)

            if llm_grad_norm > self.grad_norm_threshold:
                issues.append(f"LLM gradient exploding: {llm_grad_norm:.2f}")
            elif llm_grad_norm < 1e-6:
                issues.append(f"LLM gradient vanishing: {llm_grad_norm:.2e}")

        return {
            'healthy': len(issues) == 0,
            'issues': issues,
            'wm_grad_norm': wm_grad_norm,
            'llm_grad_norm': llm_grad_norm,
        }

    def check_loss_stability(
        self,
        wm_loss: Optional[float] = None,
        llm_loss: Optional[float] = None,
    ) -> Dict[str, any]:
        """æ£€æŸ¥æŸå¤±ç¨³å®šæ€§"""
        issues = []

        if wm_loss is not None:
            self.wm_losses.append(wm_loss)

            if len(self.wm_losses) > 10:
                recent_mean = np.mean(list(self.wm_losses)[:-1])
                if wm_loss > recent_mean * self.loss_spike_threshold:
                    issues.append(f"WM loss spike: {wm_loss:.4f} vs mean {recent_mean:.4f}")

        if llm_loss is not None:
            self.llm_losses.append(llm_loss)

            if len(self.llm_losses) > 10:
                recent_mean = np.mean(list(self.llm_losses)[:-1])
                if llm_loss > recent_mean * self.loss_spike_threshold:
                    issues.append(f"LLM loss spike: {llm_loss:.4f} vs mean {recent_mean:.4f}")

        return {
            'stable': len(issues) == 0,
            'issues': issues,
            'wm_loss': wm_loss,
            'llm_loss': llm_loss,
        }

    def check_value_distribution(
        self,
        value_mean: float,
        value_std: float,
    ) -> Dict[str, any]:
        """æ£€æŸ¥ value åˆ†å¸ƒæ˜¯å¦å¼‚å¸¸"""
        issues = []

        self.value_means.append(value_mean)
        self.value_stds.append(value_std)

        if len(self.value_means) > 10:
            historical_mean = np.mean(list(self.value_means)[:-1])
            historical_std = np.mean(list(self.value_stds)[:-1])

            mean_shift = abs(value_mean - historical_mean) / (abs(historical_mean) + 1e-8)
            std_shift = abs(value_std - historical_std) / (historical_std + 1e-8)

            if mean_shift > self.value_shift_threshold:
                issues.append(f"Value mean shift: {value_mean:.2f} vs historical {historical_mean:.2f}")

            if std_shift > self.value_shift_threshold:
                issues.append(f"Value std shift: {value_std:.2f} vs historical {historical_std:.2f}")

        return {
            'normal': len(issues) == 0,
            'issues': issues,
            'value_mean': value_mean,
            'value_std': value_std,
        }

    def get_recommendations(self) -> list[str]:
        """åŸºäºç›‘æ§ç»“æœç»™å‡ºä¼˜åŒ–å»ºè®®"""
        recommendations = []

        # Check gradient norms
        if len(self.wm_grad_norms) > 10:
            recent_wm_grad = np.mean(list(self.wm_grad_norms)[-10:])
            if recent_wm_grad > self.grad_norm_threshold * 0.5:
                recommendations.append(
                    f"WM gradient norm high ({recent_wm_grad:.2f}). "
                    f"Consider: (1) Reduce learning rate, (2) Increase gradient clipping"
                )

        if len(self.llm_grad_norms) > 10:
            recent_llm_grad = np.mean(list(self.llm_grad_norms)[-10:])
            if recent_llm_grad > self.grad_norm_threshold * 0.5:
                recommendations.append(
                    f"LLM gradient norm high ({recent_llm_grad:.2f}). "
                    f"Consider: (1) Reduce LLM learning rate, (2) Use gradient accumulation"
                )

        # Check loss trends
        if len(self.wm_losses) > 20:
            early_mean = np.mean(list(self.wm_losses)[:10])
            recent_mean = np.mean(list(self.wm_losses)[-10:])
            if recent_mean > early_mean * 1.5:
                recommendations.append(
                    f"WM loss increasing trend. "
                    f"Consider: (1) Check data quality, (2) Reduce learning rate, (3) Add regularization"
                )

        if len(self.llm_losses) > 20:
            early_mean = np.mean(list(self.llm_losses)[:10])
            recent_mean = np.mean(list(self.llm_losses)[-10:])
            if recent_mean > early_mean * 1.5:
                recommendations.append(
                    f"LLM loss increasing trend. "
                    f"Consider: (1) Pause LLM training temporarily, (2) Improve value normalization"
                )

        return recommendations

    def get_summary(self) -> Dict:
        """è·å–ç›‘æ§æ‘˜è¦"""
        summary = {
            'total_checks': len(self.wm_grad_norms),
            'warnings': self.warnings[-10:] if self.warnings else [],
            'recommendations': self.get_recommendations(),
        }

        if len(self.wm_grad_norms) > 0:
            summary['wm_grad_norm_mean'] = np.mean(list(self.wm_grad_norms))
            summary['wm_grad_norm_max'] = np.max(list(self.wm_grad_norms))

        if len(self.llm_grad_norms) > 0:
            summary['llm_grad_norm_mean'] = np.mean(list(self.llm_grad_norms))
            summary['llm_grad_norm_max'] = np.max(list(self.llm_grad_norms))

        if len(self.wm_losses) > 0:
            summary['wm_loss_mean'] = np.mean(list(self.wm_losses))
            summary['wm_loss_std'] = np.std(list(self.wm_losses))

        if len(self.llm_losses) > 0:
            summary['llm_loss_mean'] = np.mean(list(self.llm_losses))
            summary['llm_loss_std'] = np.std(list(self.llm_losses))

        return summary


class PriorZeroStabilityOptimizer:
    """
    PriorZero ç»¼åˆç¨³å®šæ€§ä¼˜åŒ–å™¨ - å¢å¼ºç‰ˆ

    æ•´åˆæ‰€æœ‰ä¼˜åŒ–æ¨¡å—ï¼Œæä¾›ç»Ÿä¸€æ¥å£

    å¢å¼ºç‰¹æ€§ï¼š
    - æ”¯æŒ Batch Welford + EMA ç»„åˆ
    - æ”¯æŒè½¯æ€§/ç¡¬æ€§è£å‰ªæ¨¡å¼
    - æ”¯æŒå¼ºåˆ¶å¯åŠ¨ä¿åº•æœºåˆ¶
    - æ”¯æŒé˜ˆå€¼æ»åé˜²éœ‡è¡
    - å®Œæ•´çš„è®­ç»ƒç¨³å®šæ€§ç›‘æ§
    """

    def __init__(
        self,
        # Value normalization config - Enhanced
        value_norm_init_momentum: float = 0.9,
        value_norm_final_momentum: float = 0.99,
        value_norm_warmup_steps: int = 100,
        value_norm_clip_method: str = 'soft',           # NEW: 'soft' or 'hard'
        value_norm_clip_percentile: float = 0.95,
        value_norm_use_welford: bool = True,

        # Curriculum training config - Enhanced
        wm_warmup_steps: int = 500,
        wm_warmup_update_ratio: int = 5,
        llm_start_threshold: float = 0.3,
        llm_start_hysteresis: float = 0.05,             # NEW: Hysteresis
        max_warmup_steps_hard_limit: int = 2000,        # NEW: Force-start limit
        min_llm_update_interval: int = 1,
        max_llm_update_interval: int = 10,
        min_llm_update_interval_hard: int = 1,          # NEW: Hard limit

        # Stability monitoring config
        grad_norm_threshold: float = 100.0,
        loss_spike_threshold: float = 3.0,
        value_shift_threshold: float = 2.0,

        # Logging
        log_interval: int = 10,
        rank: int = 0,
    ):
        self.rank = rank
        self.log_interval = log_interval
        self.step_count = 0

        # Initialize modules with enhanced parameters
        self.value_normalizer = AdaptiveValueNormalizer(
            init_momentum=value_norm_init_momentum,
            final_momentum=value_norm_final_momentum,
            warmup_steps=value_norm_warmup_steps,
            clip_method=value_norm_clip_method,
            clip_percentile=value_norm_clip_percentile,
            use_welford=value_norm_use_welford,
        )

        self.curriculum_scheduler = CurriculumTrainingScheduler(
            wm_warmup_steps=wm_warmup_steps,
            wm_warmup_update_ratio=wm_warmup_update_ratio,
            llm_start_threshold=llm_start_threshold,
            llm_start_hysteresis=llm_start_hysteresis,
            max_warmup_steps_hard_limit=max_warmup_steps_hard_limit,
            min_llm_update_interval=min_llm_update_interval,
            max_llm_update_interval=max_llm_update_interval,
            min_llm_update_interval_hard=min_llm_update_interval_hard,
        )

        self.stability_monitor = StabilityMonitor(
            grad_norm_threshold=grad_norm_threshold,
            loss_spike_threshold=loss_spike_threshold,
            value_shift_threshold=value_shift_threshold,
        )

        logging.info(f"[Rank {rank}] PriorZero Stability Optimizer (Enhanced v1.1) initialized")
        logging.info(f"  - WM warmup steps: {wm_warmup_steps}")
        logging.info(f"  - LLM start threshold: {llm_start_threshold} (hysteresis: {llm_start_hysteresis})")
        logging.info(f"  - Max warmup hard limit: {max_warmup_steps_hard_limit}")
        logging.info(f"  - Value norm: {value_norm_clip_method} clipping, Welford={value_norm_use_welford}")

    def normalize_target_values(
        self,
        target_values: torch.Tensor,
    ) -> Tuple[torch.Tensor, Dict]:
        """å½’ä¸€åŒ– target values"""
        normalized, stats = self.value_normalizer.normalize(
            target_values,
            clip_values=True,
            return_stats=True,
        )

        # Monitor value distribution
        self.stability_monitor.check_value_distribution(
            value_mean=stats['batch_mean'],
            value_std=stats['batch_std'],
        )

        return normalized, stats

    def should_train_world_model(self, new_data_collected: bool = True) -> Tuple[bool, int]:
        """åˆ¤æ–­æ˜¯å¦è®­ç»ƒ World Model"""
        return self.curriculum_scheduler.should_train_wm(new_data_collected)

    def should_train_llm(
        self,
        new_samples: int,
        value_prediction_error: Optional[float] = None,
    ) -> Tuple[bool, Dict]:
        """åˆ¤æ–­æ˜¯å¦è®­ç»ƒ LLM"""
        # Compute value prediction accuracy
        accuracy = None
        if value_prediction_error is not None:
            self.curriculum_scheduler.record_metrics(value_pred_error=value_prediction_error)
            accuracy = self.curriculum_scheduler.get_value_prediction_accuracy()

        should_train, info = self.curriculum_scheduler.should_train_llm(
            new_samples=new_samples,
            value_prediction_accuracy=accuracy,
        )

        # DDP Sync TODO
        if dist.is_initialized():
            decision = torch.tensor([float(should_train)], device='cuda')
            dist.all_reduce(decision, op=dist.ReduceOp.MAX) # åªè¦æœ‰ä¸€ä¸ª Rank æƒ³ç»ƒï¼Œå¤§å®¶å°±ä¸€èµ·ç»ƒ? æˆ–è€… MIN
            # å»ºè®®ä½¿ç”¨å¹¿æ’­ï¼šä»¥ Rank 0 ä¸ºå‡†
            # dist.broadcast(decision, src=0)
            should_train = bool(decision.item() > 0.5)
            # æ³¨æ„ï¼šå¦‚æœå¼ºåˆ¶åŒæ­¥ï¼Œinfo ä¸­çš„ reason å¯èƒ½ä¼šåœ¨ä¸åŒ rank ä¸ä¸€è‡´ï¼Œä»…ä¾›å‚è€ƒ
    

        return should_train, info

    def record_training_metrics(
        self,
        wm_loss: Optional[float] = None,
        wm_grad_norm: Optional[float] = None,
        llm_loss: Optional[float] = None,
        llm_grad_norm: Optional[float] = None,
    ):
        """è®°å½•è®­ç»ƒæŒ‡æ ‡"""
        # Record to curriculum scheduler
        self.curriculum_scheduler.record_metrics(
            wm_loss=wm_loss,
            llm_loss=llm_loss,
        )

        # Monitor stability
        if wm_grad_norm is not None or llm_grad_norm is not None:
            grad_health = self.stability_monitor.check_gradient_health(
                wm_grad_norm=wm_grad_norm,
                llm_grad_norm=llm_grad_norm,
            )
            if not grad_health['healthy'] and self.rank == 0:
                logging.warning(f"âš  Gradient health issues: {grad_health['issues']}")

        if wm_loss is not None or llm_loss is not None:
            loss_health = self.stability_monitor.check_loss_stability(
                wm_loss=wm_loss,
                llm_loss=llm_loss,
            )
            if not loss_health['stable'] and self.rank == 0:
                logging.warning(f"âš  Loss stability issues: {loss_health['issues']}")

    def step(self):
        """å‰è¿›ä¸€æ­¥"""
        self.step_count += 1
        self.curriculum_scheduler.step()

        # Periodic logging
        if self.rank == 0 and self.step_count % self.log_interval == 0:
            self._log_status()

    def _log_status(self):
        """è®°å½•å½“å‰çŠ¶æ€"""
        curriculum_stats = self.curriculum_scheduler.get_summary_stats()
        value_stats = self.value_normalizer.get_summary_stats()
        stability_summary = self.stability_monitor.get_summary()

        logging.info("="*80)
        logging.info(f"PriorZero Stability Optimizer Status (Step {self.step_count})")
        logging.info("="*80)

        logging.info("Curriculum Training:")
        logging.info(f"  - WM updates: {curriculum_stats['wm_update_count']}")
        logging.info(f"  - LLM updates: {curriculum_stats['llm_update_count']}")
        logging.info(f"  - LLM training enabled: {curriculum_stats['llm_training_enabled']}")
        logging.info(f"  - LLM ever enabled: {curriculum_stats.get('llm_ever_enabled', False)}")
        logging.info(f"  - Is warming up: {curriculum_stats['is_warming_up']}")
        if curriculum_stats['value_prediction_accuracy'] is not None:
            logging.info(f"  - Value prediction accuracy: {curriculum_stats['value_prediction_accuracy']:.3f}")

        logging.info("\nValue Normalization:")
        logging.info(f"  - Total updates: {value_stats.get('total_updates', 0)}")
        logging.info(f"  - Clip method: {value_stats.get('clip_method', 'N/A')}")
        logging.info(f"  - Current mean: {value_stats.get('current_mean', 0.0):.3f}")
        logging.info(f"  - Current std: {value_stats.get('current_std', 1.0):.3f}")
        logging.info(f"  - Recent mean: {value_stats.get('recent_mean', 0.0):.3f}")
        logging.info(f"  - Recent range: [{value_stats.get('recent_min', 0.0):.2f}, {value_stats.get('recent_max', 0.0):.2f}]")

        logging.info("\nStability Monitoring:")
        if 'wm_grad_norm_mean' in stability_summary:
            logging.info(f"  - WM grad norm (mean/max): {stability_summary['wm_grad_norm_mean']:.2f} / {stability_summary['wm_grad_norm_max']:.2f}")
        if 'llm_grad_norm_mean' in stability_summary:
            logging.info(f"  - LLM grad norm (mean/max): {stability_summary['llm_grad_norm_mean']:.2f} / {stability_summary['llm_grad_norm_max']:.2f}")
        if 'wm_loss_mean' in stability_summary:
            logging.info(f"  - WM loss (meanÂ±std): {stability_summary['wm_loss_mean']:.4f} Â± {stability_summary['wm_loss_std']:.4f}")
        if 'llm_loss_mean' in stability_summary:
            logging.info(f"  - LLM loss (meanÂ±std): {stability_summary['llm_loss_mean']:.4f} Â± {stability_summary['llm_loss_std']:.4f}")

        if stability_summary['recommendations']:
            logging.info("\nğŸ”” Recommendations:")
            for i, rec in enumerate(stability_summary['recommendations'], 1):
                logging.info(f"  {i}. {rec}")

        logging.info("="*80 + "\n")

    def get_tb_metrics(self) -> Dict:
        """è·å–ç”¨äº TensorBoard è®°å½•çš„æŒ‡æ ‡"""
        curriculum_stats = self.curriculum_scheduler.get_summary_stats()
        value_stats = self.value_normalizer.get_summary_stats()

        metrics = {
            'stability/wm_update_count': curriculum_stats['wm_update_count'],
            'stability/llm_update_count': curriculum_stats['llm_update_count'],
            'stability/llm_training_enabled': int(curriculum_stats['llm_training_enabled']),
            'stability/llm_ever_enabled': int(curriculum_stats.get('llm_ever_enabled', False)),
            'stability/is_warming_up': int(curriculum_stats['is_warming_up']),

            'stability/value_norm_mean': value_stats.get('current_mean', 0.0),
            'stability/value_norm_std': value_stats.get('current_std', 1.0),
            'stability/value_recent_mean': value_stats.get('recent_mean', 0.0),
            'stability/value_recent_std': value_stats.get('recent_std', 1.0),
        }

        if curriculum_stats['value_prediction_accuracy'] is not None:
            metrics['stability/value_prediction_accuracy'] = curriculum_stats['value_prediction_accuracy']

        if curriculum_stats['recent_wm_loss'] is not None:
            metrics['stability/wm_loss_recent'] = curriculum_stats['recent_wm_loss']

        if curriculum_stats['recent_llm_loss'] is not None:
            metrics['stability/llm_loss_recent'] = curriculum_stats['recent_llm_loss']

        if curriculum_stats['llm_loss_stability'] is not None:
            metrics['stability/llm_loss_stability'] = curriculum_stats['llm_loss_stability']

        return metrics
